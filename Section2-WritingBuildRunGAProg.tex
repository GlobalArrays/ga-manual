The GA build process has been improved by using the GNU autotools
(autoconf, automake, and libtool) as well as by combining all of the
historic GA libraries (\texttt{\textcolor{black}{linalg, armci, ma,
pario}}) into a single, monolithic \texttt{\textcolor{black}{libga}}.
Details on configuring GA can be found by running \textquotedblleft{}\texttt{\textcolor{black}{configure
\textendash{}help}}\textquotedbl{}. The following sections explain
some of the configure options a typical installation might require
for configuring and building \texttt{\textcolor{black}{libga}}, its
test programs, and how packages can link to and use GA. 

The web page \url{www.emsl.pnl.gov/docs/global/support.html} contains
information about using GA on different platforms. Please refer to
this page frequently for most recent updates and platform information.
Information on building GA on older systems is available in Appendix
C, Global Arrays on Older Systems \ref{Appendix_C}.


\section{Platform and Library Dependencies }

The following platforms are supported by Global Arrays. 


\subsection{Supported Platforms}
\begin{itemize}
\item BlueGene/L 
\item BlueGene/P 
\item Cray XT 
\item Cray XE 
\item Fujitsu 
\item IBM SP
\item Linux Cluster with Ethernet, Myrinet, Infiniband, or Quadrics
\item MAC
\item NEC 
\item SGI Altix
\item Solaris
\item Windows (Cygwin) 
\end{itemize}
For most of the platforms, there are two versions available: 32-bit
and 64-bit. 64-bit is preferred and will automatically be selected
by the configure script if the size of the C datatype \texttt{\textcolor{black}{void{*}}}
is 8 bytes. 

To aid the development of fully portable applications, in 64-bit mode
the Fortran integer datatype is 64-bits. It is motivated by 1) the
need of applications to use very large data structures, and 2) Fortran
INTEGER{*}8 not being fully portable. The 64-bit representation of
integer datatype is accomplished by using the appropriate Fortran
compiler flag. The configure script will determine this flag as needed,
but one can always override the configure script by supplying the
environment variable \texttt{\textcolor{black}{FFLAG\_INT}} e.g. \texttt{\textcolor{black}{FFLAG\_INT=-i8}}. 

\textbf{Note}: configure almost always does the right thing, so overriding
this particular option is rarely needed. The best way to enforce the
integer size of your choosing is to use the configure options \texttt{-{}-enable-i4}
or \texttt{-{}-enable-i8}. These options will force the integer size
to be 4 or 8 bytes in size, respectively. 

Because of limited interest in heterogeneous computing among known
us GA users, the Global Arrays library still does not support heterogeneous
platforms. This capability can be added if required by new applications. 


\subsection{Selection of the communication network for ARMCI }

Some cluster installations can be equipped with a high performance
network which offer instead, or in addition to, TCP/IP some special
communication protocol, for example GM on Myrinet network. To achieve
high performance in Global Arrays, \href{http://www.emsl.pnl.gov/docs/parsoft/armci}{ARMCI}
must be built to use these protocols in its implementation of one-sided
communication. Starting with GA 5.0, this is accomplished by passing
an option to the configure script. 

In addition, it might be necessary to provide a location for the header
files and library path corresponding to the location of software supporting
the appropriate protocol API. 

Our ability to automatically locate the required headers and libraries
is currently inadequate. Therefore, you will likely need to specify
the optional ARG pointing to the necessary directories and/or libraries.
Sockets is the default ARMCI network if nothing else is specified
to configure. Note that the optional argument ARG takes a quoted string
of any CPPFLAGS, LDFLAGS, or LIBS necessary for locating the headers
and libraries of the given ARMCI network. On many systems it is simply
necessary to specify the selected network: 
\begin{lyxcode}
./configure~-{}-with-openib~
\end{lyxcode}
On others, you may need to specify the path to the network's installation
if it is in a non-default location. The following will add -I/path/to/portals/install/include
and -L/path/to/portals/install/lib to the CPPFLAGS and LDFLAGS if
those directories are found to exist: 
\begin{lyxcode}
./configure~-{}-with-portals=\textquotedblright{}/path/to/portals/install\textquotedblright{}~
\end{lyxcode}
See section 2.3.1 for details of what you can pass as the quoted string
to configure options. 

\begin{tabular}{|c|c|>{\centering}p{3cm}|}
\hline 
Network & Protocol Name & Configure Option\tabularnewline
\hline
\hline 
IBM BG/L & BGML & --with-bgml\tabularnewline
\hline 
Cray shmem & Cray shmem & --with-cray-shmem\tabularnewline
\hline 
IBM BG/P & Deep Computing Message Framework & --with-dcmf\tabularnewline
\hline 
IBM LAPI & LAPI & --with-lapi\tabularnewline
\hline 
N/A & MPI Spawn - MPI-2 dynamic process management & --with-mpi-spawn\tabularnewline
\hline 
Infiniband & OpenIB & --with-openib\tabularnewline
\hline 
Cray XT & Portals & --with-portals\tabularnewline
\hline 
Ethernet & TCP/IP & --with-sockets (the default, so you don't need to specify this)\tabularnewline
\hline
\end{tabular}


\subsection{Selection of the message-passing library }

As explained in Section \ref{sec:Initialization-and-Termination},
GA works with either MPI or TCGMSG message-passing libraries. That
means GA applications can use either of these interfaces. Selection
of the message-passing library takes place when GA is configured.
Since the TCGMSG library is small and compiles fast, it is included
with the GA distribution package but as of GA 5.0 it is no longer
built by default. For GA 5.0, MPI is the default message-passing library.
There are three possible configurations for running GA with the message-passing
libraries:
\begin{enumerate}
\item \textcolor{black}{\underbar{GA with MPI}} (\emph{recommended}): directly
with MPI. In this mode, GA program should contain MPI initialization
calls. Example: \texttt{./conifigure}
\item \textcolor{black}{\underbar{GA with TCGMSG-MPI}} (MPI and TCGMSG emulation
library): TCGMSG-MPI implements functionality of TCGMSG using MPI.
In this mode, the message passing library can be initialized using
either TCGMSG PBEGIN(F) or MPI\_Init. Example: \texttt{./configure
-{}-with-mpi -{}-with-tcgmsg }
\item \textcolor{black}{\underbar{GA with TCGMSG}}: directly with TCGMSG.
In this mode, GA program should contain TCGMSG initialization calls.
Example:\texttt{ ./configure -{}-with-tcgmsg }
\end{enumerate}
For the MPI versions (1 and 2 above), the \texttt{-{}-with-mpi} configure
option can take parameters. If no parameters are specified, configure
will search for the MPI compilers. Using the MPI compilers is the
recommended way to build GA. If the MPI compilers are not found, configure
will exit with an error. The configure script will attempt to determine
the underlying Fortran 77, C, and C++ compilers wrapped by the MPI
compilers. This is necessary for other configure tests such as determining
compiler-specific optimization flags or determining the Fortran 77
libraries needed when linking using the C++ linker.

If an argument is specified to \texttt{-{}-with-mpi}, then configure
will no longer use the MPI compilers. Instead, configure will attempt
to located the MPI headers and libraries. The locations of the headers
and the locations and names of the one or more MPI libraries can differ
wildly. The argument to --with-mpi can be a quoted string of any install
paths, include paths, library paths, and/or libraries required for
compiling and linking MPI programs. See section 2.3.1 for details
of the possible arguments. 


\subsection{Dependencies on other software }

In addition to the message-passing library, GA requires (internally):
\begin{itemize}
\item \href{http://www.emsl.pnl.gov/docs/parsoft/ma/MAapi.html}{MA} (Memory
Allocator), a library for managment of local memory; 
\item \href{http://www.emsl.pnl.gov/docs/parsoft/armci}{ARMCI}, a one-sided
communication library that GA uses as its run-time system; 
\end{itemize}
GA optionally can use external: 
\begin{itemize}
\item BLAS library is required for the eigensolver and \texttt{ga\_dgemm}
(a subset is included with GA, which is built into \texttt{libga.a});
\item LAPACK library is required for the eigensolver (a subset is included
with GA, which is built into \texttt{libga.a}); 
\end{itemize}
GA may also depend on other software depending on the functions being
used.
\begin{itemize}
\item GA eigensolver, ga\_diag, is a wrapper for the eigensolver from the
PEIGS library; (Please contact \href{mailto:fanngi@ornl.gov}{George Fann}about
PEIGS) 
\item SCALAPACK, PBBLAS, and BLACS libraries are required for \emph{ga\_lu\_solve,
ga\_cholesky, ga\_llt\_solve, ga\_spd\_invert, ga\_solve}. If these
libraries are not installed, the named operations will not be available. 
\end{itemize}

\section{Writing GA Programs }

C programs that use Global Arrays should include files \emph{`global.h',
'ga.h', `macdecls.h'}. Fortran programs should include the files \emph{`mafdecls.fh',
`global.fh'}. Fortran source must be preprocessed as a part of compilation.

The GA program should look like:
\begin{itemize}
\item When GA runs with MPI\end{itemize}
\begin{lyxcode}
\textcolor{blue}{Fortran~}~~~~~~~~~~~~~~\textcolor{green}{C}

\textcolor{blue}{call~mpi\_init(..)~}~~~\textcolor{green}{MPI\_Init(..)~}~~~!~start~MPI~

\textcolor{blue}{call~ga\_initialize()}~\textcolor{green}{GA\_Initialize()~}!~start~global~arrays~

\textcolor{blue}{status~=~ma\_init(..)}~\textcolor{green}{MA\_Init(..)~}~~~~!~start~memory~allocator

\textcolor{blue}{....~do~work~~}~~~~~~~\textcolor{green}{....~do~work}

\textcolor{blue}{call~ga\_terminate()}~~\textcolor{green}{GA\_Terminate()~}~!~tidy~up~global~arrays~call

\textcolor{blue}{mpi\_finalize()}~~~~~~~\textcolor{green}{MPI\_Finalize()}~~!~tidy~up~MPI~~

\textcolor{blue}{stop}~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~!~exit~program\end{lyxcode}
\begin{itemize}
\item When GA runs with TCGMSG or TCGMSG-MPI\end{itemize}
\begin{lyxcode}
\textcolor{blue}{Fortran~C}

\textcolor{blue}{call~pbeginf()~}~~~~~~~~\textcolor{green}{PBEGIN\_(..)~}~~~~!~start~TCGMSG~

\textcolor{blue}{call~ga\_initialize()}~~~\textcolor{green}{GA\_Initialize()}~!~start~global~arrays~

\textcolor{blue}{status~=~ma\_init(..)}~~~\textcolor{green}{MA\_Init(..)}~~~~~!~start~memory~allocator

\textcolor{blue}{....~do~work~}~~~~~~~~~~~\textcolor{green}{....~do~work}

\textcolor{blue}{call~ga\_terminate()}~~~~\textcolor{green}{GA\_Terminate()~}~!~tidy~up~global~arrays~

\textcolor{blue}{call~pend()}~~~~~~~~~~~~\textcolor{green}{PEND\_()}~~~~~~~~~!~tidy~up~tcgmsg~

\textcolor{blue}{stop~}~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~!~exit~program~
\end{lyxcode}
The \emph{ma\_init }call looks like :
\begin{lyxcode}
status~=~ma\_init(type,~stack\_size,~heap\_size)
\end{lyxcode}
and it basically just goes to the OS and gets \emph{stack\_size+heap\_size}
elements of size \emph{type}. The amount of memory MA allocates need
to be sufficient for storing global arrays on some platforms. Please
refer to section \ref{sub:Memory-Allocation} for the details and
information on more advanced usage of MA in GA programs. 

MA is optional for C programs. You can replace GA\textquoteright{}s
internal MA memory handling with \texttt{malloc()} and \texttt{free()
}by using the function \texttt{GA\_Register\_stack\_memory()}.
\begin{lyxcode}
\#include~<ga.h>~

\#include~<stdlib.h>

void{*}~replace\_malloc(size\_t~bytes,~int~align,~char~{*}name)~

\{~

~~~return~malloc(bytes);~

\}

void~replace\_free(void~{*}ptr)~

\{~

~~~free(ptr);~

\}

void~replace\_ma()~

\{~

~~~GA\_Register\_stack\_memory(replace\_malloc,~replace\_free);~

\}~
\end{lyxcode}

\section{Building GA }

GNU Autotools (autoconf, automake, and libtool) are used to help build
the GA library and example programs. GA follows the usual convention
of:
\begin{lyxcode}
./configure;~make;~make~install~
\end{lyxcode}
Before GA 5.0 the user was required to set a TARGET environment variable.
This is no longer required \textendash{} the configure script will
determine the TARGET for the user. The configure script will also
search for appropriate Fortran 77, C, and C++ compilers. To override
the compilers, set the F77, CC, and/or CXX environment variables or
specify them to configure:
\begin{lyxcode}
./configure~CC=gcc~F77=ifort~CFLAGS=\textquotedblright{}-O2~-g~-Wall\textquotedbl{}
\end{lyxcode}
For the complete list of environment variables which configure recognizes,
see the output of running: 
\begin{lyxcode}
./configure~-{}-help.~
\end{lyxcode}

\subsection{Building and Running GA Test and Example Programs }

The GA distribution comes with a number of test and example programs
located in ./global/testing and ./global/examples, respectively. To
build these programs, after running configure and make, run the additional
make target: 
\begin{lyxcode}
make~checkprogs~
\end{lyxcode}
To run the GA test suite, you must tell the make program how to run
parallel programs. The following assumes either an interactive session
on a queued system or a workstation: 
\begin{lyxcode}
make~check~MPIEXEC=\textquotedblright{}mpirun~-np~4\textquotedblright{}~
\end{lyxcode}
Of course, replace the value of MPIEXEC to the appropriate command
for the MPI implementation used to build GA. The test suite has not
been tested with the TCGMSG message-passing library\textquoteright{}s
parallel.x invoker. 


\subsection{Configure Options which Take Arguments }

Certain configure options take arguments which help the configure
script locate the headers and libraries necessary for the particular
software. For example, when specifying the ARMCI network (see section
2.1.2), the location of the MPI installation (see section 2.1.3),
or specifying the location of other external software such as BLAS,
LAPACK, or ScaLAPACK. 

You can put almost anything into the quoted argument to these configure
options. For example,\texttt{ -I{*}, -L{*}, -l{*}, -Wl{*}, -WL{*},
{*}.a, {*}.so} where the asterisk represents the usual arguments to
those compiler and linker flags or paths to static or shared libraries.
Here are some sample MPI uses to illustrate our point:
\begin{lyxcode}
-{}-with-mpi=\textquotedblright{}/usr/local\textquotedblright{}~

-{}-with-mpi=\textquotedblright{}-I/usr/local/include~\textendash{}L/usr/local/lib~-lmpi\textquotedbl{}

-{}-with-mpi=\textquotedblright{}-lmpichf90~-lmpich\textquotedblright{}~
\end{lyxcode}

\subsection{BLAS and LAPACK }

The GA distribution contains a subset of the BLAS and LAPACK routines
necessary for successfully linking GA programs. However, those routines
are not optimized. If optimized BLAS and LAPACK routines are available
on your system, we recommend using them. The configure script will
automatically attempt to locate external BLAS and LAPACK libraries. 

Correctly determining the size of the Fortran INTEGER used when compiling
external BLAS and LAPACK libraries is not automatic. Even on 64-bit
platforms, external BLAS libraries are often compiled using 4-byte
Fortran INTEGERs. The GA interface to the BLAS and LAPACK routines
must match the Fortran INTEGER size used in the external BLAS and
LAPACK routines. There are three options to configure: 
\begin{itemize}
\item \texttt{-{}-with-blas{[}=ARG{]} }is the default and will attempt to
detect the size of the INTEGER, but if it fails (and it often will
since this is no easy task), it will assume 4-byte INTEGERS. Automatic
detection of the INTEGER size may improve in the future.
\item \texttt{-{}-with-blas4{[}=ARG{]}} assumes 4-byte INTEGERs 
\item \texttt{-{}-with-blas8{[}=ARG{]}} assumes 8-byte INTEGERs 
\end{itemize}
If LAPACK is in a separate library, you may need to specify \texttt{-{}-with-lapack=ARG}
where ARG is the path to the LAPACK library. See section 2.3.1 for
details. 


\subsection{ScaLAPACK }

GA interface routines to ScaLAPACK are only available when GA is built
with MPI and ScaLAPACK. Before building GA, the user is required to
configure --with-scalapack and pass the location of ScaLAPACK \& Co.
libraries passed as arguments to those configure options. See section
2.3.2 (Configure Options which Take Arguments) for details. 


\subsection{GA C++ Bindings }

The configure script automatically determines the Fortran 77 libraries
required for linking a C++ application and places them in the FLIBS
variable within the generated Makefile. Building the C++ bindings
is then as simple as specifying: 
\begin{lyxcode}
./configure~-{}-enable-cxx~
\end{lyxcode}
Running make will then link the libga++.a library in addition to the
libga.a library. Both are then required for linking C++ GA applications,
specifying libga++.a first and then libga.a (typically as -lga++ -lga). 


\subsection{Disabling Fortran }

Fortran sources have typically been used by the GA and ARMCI distributions.
For GA 5.0 and beyond, Fortran sources have been deprecated in the
ARMCI distribution and are still used by default in the GA source.
Therefore, ARMCI is free from Fortran dependencies while GA is not.
The GA dependencies can be removed by specifying 
\begin{lyxcode}
./configure~-{}-disable-f77~
\end{lyxcode}
Note that disabling Fortran 77 in GA is not well tested and doing
so will also likely disable the use of external Fortran 77 libraries
such as Fortran-based BLAS or ScaLAPACK. This also disables the use
of the GA library in Fortran applications since the MA sources will
no longer be compiled with Fortran 77 support. Use this option with
care and only if developing C and/or C++ applications exclusively. 


\subsection{Python Bindings }

GA 5.0 releases with Python bindings which were developed using the
Cython package (http://www.cython.org/). At a minimum, GA must be
configured with shared library support (which is disabled by default.)
The configure script will automatically search for a python interpreter
in the PATH environment variable, so make sure the appropriate Python
interpreter can be found before configuring. For example: 
\begin{lyxcode}
./configure~-{}-enable-shared~
\end{lyxcode}
should be all that is required to enable Python bindings. The Python
bindings are not installed by default. You should run the following: 
\begin{lyxcode}
make~python~target~
\end{lyxcode}
in order to build and install the Python bindings. The python make
target depends on the install target (i.e. \textquotedblleft{}make
install\textquotedblright{}) and will pass the libga.so and ga.h library
and header locations to the python setup.py invocation. Optionally,
you can navigate to the python source directory and run: 
\begin{lyxcode}
python~setup.py~build\_ext~
\end{lyxcode}
or 
\begin{lyxcode}
python~setup.py~build\_ext~\textendash{}inplace~
\end{lyxcode}
to build the python bindings in a more manual way. The \textquotedblleft{}make
python\textquotedblright{} target is not well tested since specifying
dependent libraries can be a difficult task. 

If GA was built with external BLAS and LAPACK, those libraries must
be specified when linking the Python shared library. Currently, users
must edit the setup.py script within the python source directory in
order to add these libraries to the standard distutils invocation
of the linker. The BLAS and LAPACK libraries on OSX are particularly
difficult to find, so this is done automatically for the user since
the configure script will detect the vecLib framework on OSX automatically.
Unforunately, at this time bulding the Python bindings is often a
manual process but those fluent in Python and Python\textquoteright{}s
\texttt{distutils} should have few problems editing the \texttt{setup.py}
script. 


\subsection{Writing and Building New GA Programs }

As of GA 5.0, the ability to place small single-file test programs
into the global/testing directory of the distribution is no longer
supported. Instead, you must install the GA headers and libraries
using the \textquotedblleft{}make install\textquotedblright{} target.
This will install the GA headers and libraries to the location specified
by the \textendash{}prefix configure option. If not specified, the
default is /\texttt{usr/local/include} and \texttt{/usr/local/lib}.
For our testing purposes, we often install GA into the same location
as the build. Recall, GA can be configured from a separate build directory,
keeping source and build trees separate. For example, from the top-level
GA source distribution: 
\begin{lyxcode}
mkdir~bld~

cd~bld~

../configure~-{}-prefix=`pwd`~

make~

make~install~
\end{lyxcode}
will configure, build, and install the GA headers and library into
the separate build directory \textquotedblleft{}bld\textquotedblright{}.
More specifically, you would find the GA library \texttt{libga} in
\texttt{./bld/lib} and the GA headers in \texttt{./bld/include}. For
packages using GA, you need to provide appropriate compiler and linker
flags to indicate the locations of the GA header files and libraries. 


\section{Running GA Programs }

Assume the GA program app.x had already been built. To run it,

\textbf{\textcolor{black}{Running on shared memory systems and clusters}}\emph{:
}(i.e., network of workstations/linux clusters)

If the app.x is built based on MPI, run the program the same way as
any other MPI programs. 

\emph{Example}: to run on four processes on clusters, use 
\begin{lyxcode}
mpirun~-np~4~app.x
\end{lyxcode}
\emph{Example}: If you are using MPICH (or MPICH-like Implementations),
and mpirun requires a machinefile or hostfile, then run the GA program
same as any other MPI programs. \textit{\textcolor{black}{The only
change required is to make sure the hostnames are specified in a consecutive
manner in the machinefile}}. Not doing this will prevent SMP optimizations
and would lead to poor resource utilization.
\begin{lyxcode}
mpirun~-np~4~-machinefile~machines.txt~app.x
\end{lyxcode}
\emph{Contents of machines.txt}: (Let us say we have two 2-way SMP
nodes (host1 and host2, and correct formats for a 4-processor machinefile
is shown in the table below).

\begin{tabular}{|>{\centering}p{2cm}|>{\centering}p{2cm}|>{\raggedright}p{3cm}|}
\hline 
Correct & Correct & Incorrect\tabularnewline
\hline
\hline 
host1

host1

host2

host2 & host2

host2

host1

host1 & host1

host2

host1 (This is wrong, the same hosts should be specified together)

host2\tabularnewline
\hline
\end{tabular}

If app.x is built based on TCGMSG (not including, Fujitsu, Cray J90,
and Windows, because there are no native ports of TCGMSG), to execute
the program on Unix workstations/servers, one should use the 'parallel'
program (built in tcgmsg/ipcv4.0). After building the application,
a file called 'app.x.p' would also be generated (If there is not such
a file, make it: 
\begin{lyxcode}
make~app.x.p
\end{lyxcode}
This file can be edited to specify how many processors and tasks to
use, and how to load the executables. Make sure that 'parallel' is
accessible (you might copy it into your 'bin' directory). To execute,
type:
\begin{lyxcode}
parallel~app.x~\end{lyxcode}
\begin{enumerate}
\item On MPPs, such as Cray XT3/XT4, or IMB SPs, use the appropriate system
command to specify the number of processors, load and run the programs.
Example: 

\begin{itemize}
\item to run on IBM SP, run as any other parallel programs (i.e., using
\emph{poe}) 
\item to run on Cray XT3/XT4, use \emph{yod}.
\end{itemize}
\item On Microsoft NT, there is no support for TCGMSG, which means you can
only build your application based on MPI. Run the application program
the same way as any other MPI programs. For, WMPI you need to create
the .pg file. Example: \end{enumerate}
\begin{lyxcode}
R:\textbackslash{}nt\textbackslash{}g\textbackslash{}global\textbackslash{}testing>~start~/b~test.exe
\end{lyxcode}

\section{Building Intel Trace Analyzer (VAMPIR) Instrumented Global Arrays}


\subsection{Introduction}

The following topics are covered in this section.
\begin{itemize}
\item New functions needed for the instrumentation 
\item Build instructions 
\item Further information 
\item Known problems
\end{itemize}

\subsection{New Functions Needed for the Instrumentation}
\begin{itemize}
\item To instrument the GA three C-functions are defined (see g/ga\_vt.c): 
\item vampir\_symdef is defined to associate integer identifiers with user
defined states and activities. It handles any errors that might occur. 
\item vampir\_begin is defined to register entering a user defined state.
It uses a global counter called <vampirtrace\_level> to avoid tracing
the use of libraries within libraries. 
\item vampir\_end is defined to register leaving a user defined state.
\end{itemize}
The interfaces of these functions are defined below.
\begin{lyxcode}
void~\textcolor{blue}{vampir\_symdef}~(int~id,~char~{*}state,~char~{*}activity,~

~~~~~~~~~~~~~~~~~~~~char~{*}file,~int~line);~

void~\textcolor{blue}{vampir\_begin}~(int~id,~char~{*}file,~int~line);~

void~\textcolor{blue}{vampir\_end}~(int~id,~char~{*}file,~int~line);
\end{lyxcode}
In addition to these functions two functions are defined to initialise
and finalise MPI when needed. The use of MPI is required because Vampirtrace
uses it internally. The functions are
\begin{lyxcode}
void~\textcolor{blue}{vampir\_init}~(int~argc,~char~{*}{*}argv,~char~{*}file,~

~~~~~~~~~~~~~~~~~~int~line);~

void~\textcolor{blue}{vampir\_finalize}~(char~{*}file,~int~line);
\end{lyxcode}
If the cpp flag -DMPI is provided then these two functions will turn
into null functions. In that case the use of MPI within the GAs will
ensure that Vampirtrace will be initialised properly.

The values for <file> and <line> are substitute with \_\_FILE\_\_
and \_\_LINE\_\_ macros. On compilation the C-preprocessor replaces
these macros with the actual file name and line number. These values
are used to generate error messages if needed. These functions are
defined in the file g/ga\_vt.h.

For each of the instrumented libraries an initialisation routine must
be defined that sets the state and activity tables up.
\begin{itemize}
\item \emph{tcgmsg}: tcgmsg\_vampir\_init in g/tcgmsg/tcgmsg\_vampir.c.
This routine is called from within PBEGINF. 
\item \emph{tcgmsg-mpi}: tcgmsg\_vampir\_init in g/tcgmsg-mpi/tcgmsg\_vampir.c
called from ALT\_PBEGIN\_ in misc.c. 
\item \emph{armci}: armci\_vampir\_init in g/armci/src/armci\_vampir.c called
from ARMCI\_Init in armci.c. 
\item \emph{global}: ga\_vampir\_init in g/global/src/ga\_vampir.c called
from ga\_initialize\_ and ga\_initialize\_ltd\_ in global.armci.c
\end{itemize}

\subsection{Build Instructions }

To build GA with Vampir (now called, Intel Trace Analyzer) set the
environment variable GA\_USE\_VAMPIR.

e.g., \texttt{\textcolor{black}{setenv GA\_USE\_VAMPIR y}}

to compile the GAs including all the Vampirtrace instrumentation.
Further environment variables that are required are
\begin{lyxcode}
LIBVT~:~The~name~of~the~library,~normally~-lVT~which~

~~~~~~~~~~~~~is~the~default.~

VT\_LIB~:~The~path~to~the~library,~-L<library-path>~

~~~~~~~~~~~~~e.g.~setenv~VT\_LIB~/usr/local/vampir/lib~

VT\_INCLUDE:~The~path~to~the~include~file~VT.h,~

~~~~~~~~~~~~-I<include-path>.~e.g.~setenv~VT\_INCLUDE

~~~~~~~~~~~~/usr/local/vampir/include
\end{lyxcode}
On some platforms it may be necessary to set LIBMPI to -lpmpi to load
the MPI profile interfaces that vampirtrace needs.

There are no defaults for VT\_PATH and VT\_INCLUDE. Beyond this point
simply follow the GA make instructions.

\noun{Note: }that libVT.a should be loaded before mpi or pmpi otherwise
the vampirtracing will be ignored. 


\subsection{Further Information }

More information on using Intel Trace Analyzer can be found on the
Intel website at

\href{http://www.intel.com/software/products/cluster/tanalyzer/}{http://www.intel.com/software/products/cluster/tanalyzer/}

From this location Vampir and Vampirtrace can be downloaded for various
platforms including validation licenses if needed.


\subsection{Known Problems}
\begin{itemize}
\item Vampirtrace and LAM-MPI clash
\end{itemize}
In an attempt to produce traces while running with LAM-MPI the program
would always abort in MPI\_Init due to a segmentation violation. The
Pallas website does not mention LAM-MPI at all, but does explicitly
state that Vampirtrace does work with MPICH. Indeed the latter has
been confirmed in tests. Therefore it is not recommended to use the
Vampirtrace instrumentation with LAM-MPI. 
